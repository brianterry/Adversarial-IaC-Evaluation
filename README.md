# Adversarial IaC Evaluation

**Adversarial Evaluation of Multi-Agent LLM Systems for Secure Infrastructure-as-Code**

This research project implements a Red Team vs Blue Team evaluation framework for assessing LLM capabilities in Infrastructure-as-Code security. It builds upon the [Vulnerable IaC Dataset Generator](https://github.com/SymbioticSec/vulnerable-iac-dataset-generator) and extends it with adversarial evaluation capabilities.

## Research Overview

This project addresses the research question: *How well can LLMs generate and detect security vulnerabilities in Infrastructure-as-Code?*

### Key Features

- **Red Team Agent**: Generates plausible but vulnerable IaC that attempts to evade detection
- **Blue Team Agent**: Detects vulnerabilities using LLM reasoning and static analysis tools
- **Judge System**: Scores matches between injected vulnerabilities and detections
- **Multi-Model Evaluation**: Compare different foundation models on Amazon Bedrock
- **Difficulty Levels**: Easy, Medium, Hard vulnerability injection strategies

### How a Game Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ADVERSARIAL IaC GAME FLOW                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         
     â”‚   SCENARIO   â”‚  "Create S3 bucket for PHI data with security controls" 
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                         
            â”‚                                                                 
            â–¼                                                                 
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”´ RED TEAM (Attacker)                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Receives scenario + difficulty level (medium/hard)              â”‚  â”‚
â”‚  â”‚  2. Generates legitimate-looking Terraform code                     â”‚  â”‚
â”‚  â”‚  3. Injects 3-5 hidden vulnerabilities using stealth techniques     â”‚  â”‚
â”‚  â”‚  4. Outputs: code files + secret vulnerability manifest             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                                                 
            â”‚  Terraform Code                                                 
            â”‚  (vulnerabilities hidden)                                       
            â–¼                                                                 
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”µ BLUE TEAM (Defender)                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Receives ONLY the code (no knowledge of hidden vulns)           â”‚  â”‚
â”‚  â”‚  2. Analyzes code for security issues                               â”‚  â”‚
â”‚  â”‚  3. Reports all detected vulnerabilities with evidence              â”‚  â”‚
â”‚  â”‚  4. Outputs: list of findings with severity + location              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                                                 
            â”‚  Blue Team Findings                                             
            â–¼                                                                 
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âš–ï¸  JUDGE                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Compares: Red Team's secret manifest vs Blue Team's findings       â”‚  â”‚
â”‚  â”‚                                                                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚  â”‚
â”‚  â”‚  â”‚  RED MANIFEST   â”‚         â”‚  BLUE FINDINGS  â”‚                    â”‚  â”‚
â”‚  â”‚  â”‚  (Ground Truth) â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚  (Detections)   â”‚                    â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ V1: No enc   â”‚         â”‚  â€¢ F1: No enc âœ“ â”‚  â† Match!          â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ V2: Public   â”‚         â”‚  â€¢ F2: Public âœ“ â”‚  â† Match!          â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ V3: Weak IAM â”‚         â”‚  â€¢ F3: Logging  â”‚  â† False Positive  â”‚  â”‚
â”‚  â”‚  â”‚                 â”‚         â”‚                 â”‚                    â”‚  â”‚
â”‚  â”‚  â”‚  V3 = EVADED    â”‚         â”‚  F3 = WRONG     â”‚                    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                                                 
            â–¼                                                                 
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š SCORING                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Precision = TP/(TP+FP)  â†’ "How accurate were Blue's reports?"      â”‚  â”‚
â”‚  â”‚  Recall    = TP/(TP+FN)  â†’ "How many vulns did Blue find?"          â”‚  â”‚
â”‚  â”‚  F1 Score  = Balance of precision & recall                          â”‚  â”‚
â”‚  â”‚  Evasion   = FN/Total    â†’ "How many vulns did Red hide?"           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend:
  TP = True Positive  (Blue correctly found Red's vulnerability)
  FP = False Positive (Blue reported something that wasn't a real vuln)
  FN = False Negative (Red's vulnerability that Blue missed)
```

## Installation

### Quick Install

```bash
# Clone with submodule (recommended)
git clone --recursive https://github.com/brianterry/Adversarial-IaC-Evaluation.git
cd Adversarial-IaC-Evaluation

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install the package (includes CLI and dependencies)
pip install -e .
```

### If You Already Cloned (without --recursive)

```bash
# Initialize the vulnerability database submodule
git submodule update --init --recursive
```

### Verify Installation

```bash
# Test that everything works
python -c "from src.agents.red_team_agent import VulnerabilityDatabase; db = VulnerabilityDatabase(); print(f'âœ“ Loaded {len(db.get_sample_for_prompt(\"aws\", \"terraform\").get(\"sample_vulnerabilities\", []))} vulnerability rules')"
```

Expected output:
```
âœ“ Loaded 20 vulnerability rules
```

### What the Submodule Provides

The `vendor/vulnerable-iac-generator` submodule contains:
- **142 Trivy vulnerability rules** for AWS, Azure, and GCP
- **Real-world misconfiguration patterns** from security research
- **Multi-cloud support**: Terraform (AWS, Azure, GCP), CloudFormation, ARM templates

âš ï¸ **The submodule is required.** The system will fail with a clear error message if not initialized.

### Optional: Install Static Analysis Tools

For hybrid detection mode (LLM + static tools):

```bash
# Install Trivy (macOS)
brew install trivy

# Install Checkov
pip install checkov
```

## Project Structure

```
adversarial-iac-eval/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ red_team_agent.py    # Adversarial IaC generator
â”‚   â”‚   â”œâ”€â”€ blue_team_agent.py   # Vulnerability detector
â”‚   â”‚   â””â”€â”€ judge_agent.py       # Scoring and matching
â”‚   â”œâ”€â”€ game/
â”‚   â”‚   â”œâ”€â”€ engine.py            # Game orchestration
â”‚   â”‚   â””â”€â”€ scenarios.py         # Test scenario generation
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ trivy_runner.py      # Trivy scanner integration
â”‚   â”‚   â””â”€â”€ checkov_runner.py    # Checkov scanner integration
â”‚   â”œâ”€â”€ prompts.py               # Adversarial prompts
â”‚   â””â”€â”€ cli.py                   # Command-line interface
â”œâ”€â”€ vendor/
â”‚   â””â”€â”€ vulnerable-iac-generator/  # Git submodule (142 Trivy rules)
â”‚       â”œâ”€â”€ data/trivy_rules_db.json
â”‚       â””â”€â”€ src/utils/vulnerability_db.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ experiment_config.yaml   # Full experiment configuration
â”‚   â””â”€â”€ experiment_small.yaml    # Small test configuration
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_single_game.ipynb     # Interactive single game
â”‚   â””â”€â”€ 02_run_experiment.ipynb  # Batch experiments
â”œâ”€â”€ experiments/                  # Experiment results
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ pyproject.toml               # Package configuration
```

## Quick Start

### Run a Single Game

```bash
# Red Team (Claude Sonnet) vs Blue Team (Nova Pro)
adversarial-iac game \
    --red-model us.anthropic.claude-3-5-sonnet-20241022-v2:0 \
    --blue-model amazon.nova-pro-v1:0 \
    --scenario "Create an S3 bucket for healthcare PHI data" \
    --difficulty medium
```

### Run Full Experiment

```bash
# Run symmetric adversarial experiment (same model attacks/defends)
adversarial-iac experiment \
    --config config/experiment_config.yaml \
    --experiment symmetric_adversarial \
    --output experiments/exp_001
```

### Analyze Results

```bash
# Generate analysis report
adversarial-iac analyze \
    --experiment experiments/exp_001 \
    --output-format latex,csv,figures
```

## Experiment Configuration

Experiments are configured using YAML files in the `config/` directory. Two configurations are provided:

- `experiment_config.yaml` - Full experiment (~480 games, ~6 hours)
- `experiment_small.yaml` - Small test experiment (~24 games, ~20 minutes)

### Configuration File Structure

```yaml
# Required: Experiment metadata
experiment:
  name: "my_experiment"           # Unique experiment name
  description: "Description"      # Human-readable description
  output_dir: "experiments/out"   # Where to save results
  random_seed: 42                 # Optional: for reproducibility

# Required: AWS Bedrock settings
aws:
  region: "us-east-1"             # AWS region for Bedrock API calls

# Required: Models to evaluate
models:
  - id: "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
    name: "Claude 3.5 Sonnet v2"  # Display name
    provider: "anthropic"          # Model provider
    tier: "flagship"               # Optional: categorization

# Required: At least one difficulty level
difficulty_levels:
  - easy      # Basic vulnerabilities, obvious misconfigurations
  - medium    # Subtle issues requiring context to detect
  - hard      # Complex, chained vulnerabilities with evasion techniques

# Required: IaC languages
languages:
  - terraform
  - cloudformation

# Required: Cloud providers
cloud_providers:
  - aws
  # - azure    # Future support
  # - gcp      # Future support
```

### Scenarios Configuration

Define what infrastructure scenarios to test:

```yaml
scenarios:
  # Option 1: Generate scenarios per domain
  domains:
    - storage      # S3, encryption, access control
    - compute      # EC2, Lambda, security groups
    - network      # VPC, subnets, routing
    - iam          # Roles, policies, permissions
    - multi_service # Complex multi-resource architectures
  scenarios_per_domain: 2  # How many scenarios per domain

  # Option 2: Define specific scenarios explicitly
  specific_scenarios:
    - domain: storage
      description: "Create an S3 bucket for storing healthcare PHI data"
    - domain: compute
      description: "Create a Lambda function that processes credit card transactions"
    - domain: iam
      description: "Create IAM roles for a CI/CD pipeline"
```

### Game Configuration

Control timing and retry behavior:

```yaml
game:
  rounds_per_game: 1        # Games per scenario (for statistical significance)
  red_team_timeout: 120     # Max seconds for Red Team generation
  blue_team_timeout: 120    # Max seconds for Blue Team analysis
  max_retries: 2            # Retry attempts on failure
  retry_delay: 5            # Seconds between retries
```

### Experiment Types

Three experiment types can be enabled/disabled:

```yaml
experiments:
  # Symmetric: Same model plays both Red and Blue Team
  symmetric:
    enabled: true
    description: "Tests model's ability to find its own vulnerabilities"

  # Asymmetric: Different models compete against each other
  asymmetric:
    enabled: true
    description: "Tests relative model capabilities"
    model_pairs:
      - red: "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
        blue: "us.anthropic.claude-3-5-haiku-20241022-v1:0"
      - red: "us.anthropic.claude-3-5-haiku-20241022-v1:0"
        blue: "us.anthropic.claude-3-5-sonnet-20241022-v2:0"

  # Tool-assisted: Blue Team uses Trivy/Checkov in addition to LLM
  tool_assisted:
    enabled: true
    description: "Tests LLM + static analysis tool combination"
```

### Output Settings

Control what gets saved:

```yaml
output:
  save_code: true           # Save generated IaC files
  save_manifests: true      # Save vulnerability ground truth
  save_findings: true       # Save Blue Team detection results
  save_raw_llm: false       # Save raw LLM responses (large files)
  formats:
    - json                  # Machine-readable results
    - csv                   # Spreadsheet-compatible
    - latex                 # Paper-ready tables
```

### Calculating Experiment Size

The total number of games depends on your configuration:

| Experiment Type | Formula |
|-----------------|---------|
| **Symmetric** | `models Ã— scenarios Ã— difficulties` |
| **Asymmetric** | `model_pairs Ã— scenarios Ã— difficulties` |
| **Tool-Assisted** | `models Ã— scenarios Ã— difficulties` (with tools enabled) |

**Example calculation** (small config):
- 2 models Ã— 3 scenarios Ã— 2 difficulties = **12 symmetric games**
- 2 pairs Ã— 3 scenarios Ã— 2 difficulties = **12 asymmetric games**
- **Total: 24 games** (~20 minutes, ~$5-10)

### Running Experiments

```bash
# Run with default config
python run_small_experiment.py

# Preview what will run (dry-run)
python run_small_experiment.py --dry-run

# Run limited number of games
python run_small_experiment.py --limit 5

# Use custom config
python run_small_experiment.py --config config/my_config.yaml
```

### CLI Commands

Individual game commands are also available:

```bash
# Run Red Team attack only
adversarial-iac red-team \
    --scenario "Create S3 bucket for PHI" \
    --model us.anthropic.claude-3-5-sonnet-20241022-v2:0 \
    --difficulty medium

# Run Blue Team analysis on existing code
adversarial-iac blue-team \
    --input-dir output/red-team/run_xxx \
    --model us.anthropic.claude-3-5-sonnet-20241022-v2:0 \
    --mode llm_only

# Score Blue Team findings against ground truth
adversarial-iac score \
    --red-dir output/red-team/run_xxx \
    --blue-dir output/blue-team/run_xxx

# Run complete game (Red + Blue + Scoring)
adversarial-iac game \
    --scenario "Create S3 bucket for PHI" \
    --red-model us.anthropic.claude-3-5-haiku-20241022-v1:0 \
    --blue-model us.anthropic.claude-3-5-sonnet-20241022-v2:0 \
    --difficulty hard
```

### Environment Variables

Required environment variables (set in `.env` or export):

```bash
AWS_REGION=us-east-1              # AWS region for Bedrock
AWS_ACCESS_KEY_ID=xxx             # AWS credentials
AWS_SECRET_ACCESS_KEY=xxx
# Or use AWS_PROFILE for credential profiles
```

## Understanding the Scoring System

This section explains how we measure performance in the adversarial evaluation. Don't worry if you're not familiar with these metricsâ€”we'll explain each one with simple examples.

### The Basic Idea

Think of this like a game of hide-and-seek:
- **Red Team (Attacker)**: Hides security vulnerabilities in the code
- **Blue Team (Defender)**: Tries to find all the hidden vulnerabilities
- **Judge**: Compares what was hidden vs. what was found

### How the Judge Works

The Judge Agent is responsible for fairly scoring each game. Since vulnerabilities can be described differently by Red Team and Blue Team, the Judge uses a **multi-criteria matching algorithm**.

#### The Matching Process

```
For each Red Team vulnerability:
    1. Compare against all Blue Team findings
    2. Calculate a match score (0.0 - 1.0)
    3. Keep the best match above threshold
    4. Mark unmatched vulnerabilities as "evaded"
```

#### Match Score Calculation

The Judge scores each potential match based on four criteria:

| Criterion | Weight | What It Checks |
|-----------|--------|----------------|
| **Resource Name** | 40% | Is it the same resource? (e.g., `aws_s3_bucket.data`) |
| **Vulnerability Type** | 20% | Same category? (encryption, IAM, network, etc.) |
| **Attribute Match** | 20% | Is the specific vulnerable attribute mentioned? |
| **Keyword Overlap** | 10% | Do titles/descriptions share key terms? |

#### Example Match Calculation

```
Red Team Vulnerability:
  - Resource: aws_s3_bucket.phi_data
  - Type: encryption
  - Attribute: server_side_encryption
  - Title: "PHI bucket missing KMS encryption"

Blue Team Finding:
  - Resource: aws_s3_bucket.phi_data     â†’ +0.40 (exact match)
  - Type: encryption                      â†’ +0.20 (exact match)
  - Evidence: "no encryption configured"  â†’ +0.15 (attribute in evidence)
  - Title: "S3 bucket not encrypted"      â†’ +0.10 (keyword overlap)
  
Total Score: 0.85 â†’ "exact" match âœ“
```

#### Match Types

| Score Range | Match Type | Meaning |
|-------------|------------|---------|
| â‰¥ 0.70 | **Exact** | Clear match, counted as True Positive |
| 0.40 - 0.69 | **Partial** | Related finding, still counted as True Positive |
| 0.30 - 0.39 | **Weak** | Borderline, may be coincidental |
| < 0.30 | **Missed** | Vulnerability evaded detection (False Negative) |

#### Related Type Recognition

The Judge understands that some vulnerability types are related:

```
encryption â†” data_protection   (both about protecting data)
access_control â†” iam           (both about permissions)
network â†” access_control       (both about who can connect)
logging â†” monitoring           (both about visibility)
```

If types are related, a partial score (0.10) is still awarded.

#### Why Not Use Exact String Matching?

Red Team and Blue Team describe vulnerabilities differently:

| Red Team Says | Blue Team Says | Same Issue? |
|---------------|----------------|-------------|
| "No KMS encryption on S3" | "S3 bucket not encrypted at rest" | âœ… Yes |
| "IAM policy too permissive" | "Role has excessive privileges" | âœ… Yes |
| "Missing access logging" | "No CloudTrail logging enabled" | âš ï¸ Maybe |

The Judge's scoring system handles these semantic differences while maintaining fairness.

### Example Game

Let's say Red Team hides **5 vulnerabilities** in the code, and Blue Team reports **6 findings**:

```
Red Team hid:        Blue Team found:
â”œâ”€â”€ V1: No encryption     â”œâ”€â”€ F1: No encryption â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Match! âœ“
â”œâ”€â”€ V2: Public bucket     â”œâ”€â”€ F2: Public bucket â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Match! âœ“
â”œâ”€â”€ V3: Weak IAM policy   â”œâ”€â”€ F3: Weak IAM policy â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Match! âœ“
â”œâ”€â”€ V4: No logging        â”œâ”€â”€ F4: Missing versioning â”€â”€â”€â”€â”€â”€â–º Wrong (False Positive)
â””â”€â”€ V5: Open firewall     â”œâ”€â”€ F5: No logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Match! âœ“
                          â””â”€â”€ F6: Hardcoded secret â”€â”€â”€â”€â”€â”€â”€â”€â–º Wrong (False Positive)
```

In this example:
- **4 correct detections** (True Positives): V1, V2, V3, V4 were found
- **1 missed vulnerability** (False Negative): V5 was not detected
- **2 false alarms** (False Positives): F4 and F6 weren't real vulnerabilities

### Key Metrics Explained

#### Precision: "How accurate were the detections?"

> *Of everything Blue Team reported, how many were actually real vulnerabilities?*

```
Precision = Correct Detections / Total Reported
          = 4 / 6
          = 66.7%
```

**Plain English**: "Blue Team was right about 67% of the issues it flagged."

A **low precision** means too many false alarmsâ€”the detector is "crying wolf."

#### Recall: "How complete was the detection?"

> *Of all the vulnerabilities that existed, how many did Blue Team find?*

```
Recall = Correct Detections / Total Hidden
       = 4 / 5
       = 80%
```

**Plain English**: "Blue Team found 80% of the hidden vulnerabilities."

A **low recall** means vulnerabilities are slipping throughâ€”the detector has blind spots.

#### F1 Score: "Overall detection quality"

> *A single number that balances precision and recall*

The F1 Score combines both metrics. It's high only when **both** precision and recall are high.

```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
   = 2 Ã— (0.667 Ã— 0.80) / (0.667 + 0.80)
   = 72.7%
```

**Plain English**: "Overall, Blue Team performed at about 73% effectiveness."

| F1 Score | Interpretation |
|----------|----------------|
| 90-100%  | Excellent detection |
| 70-89%   | Good detection |
| 50-69%   | Moderateâ€”room for improvement |
| Below 50% | Poorâ€”significant blind spots |

#### Evasion Rate: "How sneaky was Red Team?"

> *What percentage of vulnerabilities escaped detection?*

```
Evasion Rate = Missed Vulnerabilities / Total Hidden
             = 1 / 5
             = 20%
```

**Plain English**: "Red Team successfully hid 20% of vulnerabilities from Blue Team."

A **high evasion rate** means the attacker is winningâ€”the vulnerabilities are too subtle to detect.

### Visual Summary

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         WHAT BLUE TEAM REPORTED         â”‚
                    â”‚                                         â”‚
                    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚   â”‚  TRUE POSITIVES â”‚ FALSE POSITIVES â”‚ â”‚
                    â”‚   â”‚   (Correct!)    â”‚ (False Alarms)  â”‚ â”‚
  WHAT ACTUALLY     â”‚   â”‚                 â”‚                 â”‚ â”‚
  EXISTED           â”‚   â”‚    4 found      â”‚    2 wrong      â”‚ â”‚
  (Red Team hid)    â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
                    â”‚   â”‚ FALSE NEGATIVES â”‚                 â”‚ â”‚
                    â”‚   â”‚    (Missed!)    â”‚                 â”‚ â”‚
                    â”‚   â”‚                 â”‚                 â”‚ â”‚
                    â”‚   â”‚    1 evaded     â”‚                 â”‚ â”‚
                    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Precision = 4 / (4+2) = 67%  â† "How many reports were correct?"
  Recall    = 4 / (4+1) = 80%  â† "How many vulns were found?"
  F1 Score  = ~73%             â† "Overall effectiveness"
  Evasion   = 1 / 5    = 20%   â† "How many escaped?"
```

### Real Results from Our Experiment

Here's what we observed in our 24-game experiment:

| Metric | Average | What It Means |
|--------|---------|---------------|
| **Precision** | 62% | About 6 in 10 reported issues were real vulnerabilities |
| **Recall** | 60% | About 6 in 10 vulnerabilities were detected |
| **F1 Score** | 59% | Moderate overall performance |
| **Evasion Rate** | 24% | About 1 in 4 vulnerabilities escaped detection |

### Why These Metrics Matter

For **security research**, these metrics reveal:

1. **Can we trust LLM security scanners?** 
   - 62% precision means 38% false positivesâ€”noisy but useful
   
2. **Are LLMs missing critical vulnerabilities?**
   - 24% evasion rate means real risks slip through
   
3. **Which is harder: attacking or defending?**
   - Our data shows attacking is easier (especially with stronger models)

### Stealth Score: "Did the code look legitimate?"

Beyond detection metrics, we also measure whether Red Team's code looks real:

| Score | Meaning |
|-------|---------|
| **1** | Code passes syntax validation (looks legitimate) |
| **0** | Code has obvious errors (suspicious) |

A good Red Team generates code that:
- Passes `terraform validate` or `cfn-lint`
- Looks like normal infrastructure code
- Has realistic resource names and comments
- Hides vulnerabilities in plain sight

### Game Output Files

After each game, the following files are saved to `output/games/<game_id>/`:

| File | Description |
|------|-------------|
| `code/main.tf` | Generated IaC code (Terraform or CloudFormation) |
| `code/variables.tf` | Variable definitions |
| `red_manifest.json` | Ground truth - vulnerabilities injected by Red Team |
| `blue_findings.json` | Vulnerabilities detected by Blue Team |
| `scoring.json` | Match results with precision, recall, F1 score |
| `metadata.json` | Game configuration and summary metrics |
| `game.log` | Complete text log of the game execution |

The `game.log` file contains a detailed trace of everything that happened during the game, including LLM calls, tool execution, and timing information - useful for debugging and analysis.

### Reading Judge Output Files

After each game, the Judge produces a `scoring.json` file with detailed results:

```json
{
  "metrics": {
    "precision": 0.67,
    "recall": 0.80,
    "f1_score": 0.73,
    "evasion_rate": 0.20
  },
  "counts": {
    "total_red_vulns": 5,
    "total_blue_findings": 6,
    "true_positives": 4,
    "false_positives": 2,
    "false_negatives": 1,
    "exact_matches": 3,
    "partial_matches": 1
  },
  "matches": [
    {
      "red_vuln_id": "V1",
      "blue_finding_id": "LLM-1",
      "match_type": "exact",
      "confidence": 0.85,
      "explanation": "Exact match: 'No encryption' was detected as 'S3 not encrypted'"
    },
    {
      "red_vuln_id": "V5",
      "blue_finding_id": null,
      "match_type": "missed",
      "confidence": 0.0,
      "explanation": "Missed: 'Open firewall' on aws_security_group.web was not detected"
    }
  ]
}
```

**Key fields explained:**

| Field | Meaning |
|-------|---------|
| `exact_matches` | Blue Team found the exact vulnerability |
| `partial_matches` | Blue Team found something related but not exact |
| `confidence` | How certain the Judge is about the match (0.0-1.0) |
| `match_type` | `exact`, `partial`, or `missed` |

### Using Judge Results for Research

The detailed match data enables research questions like:

1. **Which vulnerability types are hardest to detect?**
   - Filter matches by Red Team's `type` field
   - Calculate detection rate per category

2. **Does model size affect detection?**
   - Compare F1 scores across different Blue Team models

3. **Are certain Red Team strategies more effective?**
   - Correlate `stealth_technique` with `match_type`

```python
# Example: Find most commonly evaded vulnerability types
import json

results = json.load(open("scoring.json"))
evaded = [m for m in results["matches"] if m["match_type"] == "missed"]
# Analyze which types appear most in evaded list
```

## Tool Comparison: LLM vs Static Analysis

One key research question is: **How do LLMs compare to traditional static analysis tools?**

We tested three detection approaches on adversarially-generated vulnerable IaC:

### Detection Methods

| Tool | Type | How It Works |
|------|------|--------------|
| **LLM** | Semantic | Reasons about code meaning, context, and security implications |
| **Trivy** | Pattern | Matches known vulnerability signatures |
| **Checkov** | Policy | Checks against predefined security rules |

### Experimental Results

We ran all three tools against 20 games with 78 ground-truth vulnerabilities:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tool        â”‚ Findings   â”‚ Games Detected  â”‚ Detection Rate    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LLM         â”‚        101 â”‚           20/20 â”‚            100.0% â”‚
â”‚ Trivy       â”‚          0 â”‚            0/20 â”‚              0.0% â”‚
â”‚ Checkov     â”‚         87 â”‚           20/20 â”‚            100.0% â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Findings

1. **Trivy found zero vulnerabilities** across all games
   - Why? Our Red Team generates *subtle, contextual* vulnerabilities
   - Trivy looks for explicit patterns (hardcoded secrets, known misconfigs)
   - It misses "missing resource" and "semantic" vulnerabilities entirely

2. **Checkov found 87 issues** (4.3 per game)
   - Better coverage through policy-as-code rules
   - Still misses context-dependent vulnerabilities
   - High precision (when it finds something, it's usually real)

3. **LLM found 101 issues** (5.0 per game)
   - Highest raw detection rate
   - Can detect semantic vulnerabilities (missing logging, insufficient encryption)
   - May have more false positives (needs ground-truth validation)

### What This Means

| Vulnerability Type | LLM | Checkov | Trivy |
|--------------------|-----|---------|-------|
| Missing encryption | âœ… Detects | âš ï¸ Sometimes | âŒ Misses |
| Missing logging | âœ… Detects | âŒ Misses | âŒ Misses |
| Public access | âœ… Detects | âœ… Detects | âŒ Misses |
| Overly permissive IAM | âœ… Detects | âš ï¸ Sometimes | âŒ Misses |
| Hardcoded secrets | âœ… Detects | âœ… Detects | âœ… Detects |

### Hybrid Detection Results

We ran a hybrid experiment combining LLM + Checkov:

```
                      Hybrid Detection Results                      
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
â”ƒ Game            â”ƒ  GT â”ƒ Hybrid â”ƒ LLM â”ƒ Checkov â”ƒ    F1 â”ƒ Evasion â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
â”‚ Storage-Medium  â”‚   3 â”‚      4 â”‚   3 â”‚       1 â”‚ 33.3% â”‚   66.7% â”‚
â”‚ Storage-Hard    â”‚   5 â”‚      6 â”‚   5 â”‚       1 â”‚ 40.0% â”‚   60.0% â”‚
â”‚ Compute-Medium  â”‚   3 â”‚      8 â”‚   5 â”‚       3 â”‚ 22.2% â”‚   66.7% â”‚
â”‚ Compute-Hard    â”‚   5 â”‚      9 â”‚   5 â”‚       4 â”‚ 57.1% â”‚   20.0% â”‚
â”‚ IAM-Medium      â”‚   3 â”‚      5 â”‚   3 â”‚       2 â”‚ 50.0% â”‚   33.3% â”‚
â”‚ IAM-Hard        â”‚   5 â”‚      7 â”‚   4 â”‚       3 â”‚ 50.0% â”‚   40.0% â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Aggregate Metrics:
  Average F1 Score: 35.44%
  Average Evasion Rate: 31.18%
  Total Hybrid Findings: 162 (LLM: 97, Checkov: 65)
```

**Key Takeaways:**

| Approach | Strengths | Weaknesses |
|----------|-----------|------------|
| **LLM Only** | High recall, semantic understanding | May hallucinate, higher cost |
| **Checkov Only** | High precision, fast, free | Misses contextual issues |
| **Hybrid** | Best coverage, combines strengths | More false positives, slower |

**Conclusion**: LLMs provide *complementary* security detection capabilities. The best approach may be **hybrid** (LLM + static tools) with intelligent deduplication.

### Running Tool Comparison

```bash
# Compare LLM vs Trivy vs Checkov on existing experiment
adversarial-iac compare-tools \
    --experiment experiments/small_test/exp_20260220_125729

# Run hybrid (LLM + Checkov) experiment
adversarial-iac hybrid-experiment \
    --experiment experiments/small_test/exp_20260220_125729 \
    --model us.anthropic.claude-3-5-haiku-20241022-v1:0

# Run Blue Team with different modes
adversarial-iac blue-team --mode llm_only --input-dir output/red-team/run_xxx
adversarial-iac blue-team --mode tools_only --use-checkov --input-dir output/red-team/run_xxx
adversarial-iac blue-team --mode hybrid --use-checkov --input-dir output/red-team/run_xxx
```

### Tool Installation

```bash
# Install Trivy (macOS)
brew install trivy

# Install Checkov
pip install checkov

# Verify installation
trivy --version   # Should show 0.69.1+
checkov --version # Should show 3.2.504+
```

## Updating the Vulnerability Database

The vulnerability rules come from a git submodule. To get the latest rules:

```bash
# Update the submodule to latest commit
git submodule update --remote vendor/vulnerable-iac-generator

# Commit the update
git add vendor/vulnerable-iac-generator
git commit -m "Update vulnerability database"
```

## Related Work

This project extends:
- Terry et al. (2025). "Evaluation of Foundation Models for IaC Automation on Amazon Bedrock." IEEE CARS 2025.

## Citation

```bibtex
@inproceedings{terry2025adversarial,
  title={Adversarial Evaluation of Multi-Agent LLM Systems for Secure Infrastructure-as-Code},
  author={Terry, Brian and others},
  booktitle={TBD},
  year={2025}
}
```

## License

MIT License
